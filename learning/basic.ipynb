{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "969e0b31-342f-418e-a154-7198b2caa172",
   "metadata": {},
   "source": [
    "Tensor is the mathematical object used to store data in multiple dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a48c75d-4ea3-4810-8f25-db7cc2a8c2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1.post100\n",
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65957c7-1441-495e-81a1-3505b46566ca",
   "metadata": {},
   "source": [
    "### check for gpu access with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ee31008b-287e-4a23-860e-8dee20f9e609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257c5fe9-c36a-49e1-8a5b-1a0cbe5f1f23",
   "metadata": {},
   "source": [
    "## Creating tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512eca9c-4c93-4d60-857b-6ea62521f170",
   "metadata": {},
   "source": [
    "torch.tensor is function, used to create tensor, which is similar to multi-dimension numpy array but optimized for gpu acceleration and auto differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004bdfa5-c06d-4515-99ca-42136f519172",
   "metadata": {},
   "source": [
    "#### Type:-1 Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "995bdb75-97cf-4b9b-b05a-fffc528c83ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f6474de-20ff-494e-bd5b-250f1a6df468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find dimensions of a tensor\n",
    "scalar.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "184287a7-e324-4ee5-83f8-7d0dba7c7d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get tensor back as a python int\n",
    "# .item only works with scalar\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0735c-bb34-48d5-8e8f-ee18078a5a84",
   "metadata": {},
   "source": [
    "#### Type:-2 Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8feeae08-7b50-4302-ae5e-46dcec0c1d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([4,5])\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d553dfb0-1bcb-439d-bca9-fdc4f4b260e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .shape return the size of each dimension\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52904d76-b295-4e5d-b4cc-3ea516881cf5",
   "metadata": {},
   "source": [
    "#### Type:-3 Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f77b38ee-1054-44d0-a114-3669732d91a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[7,2], [3,5]])\n",
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4e6af80-d69e-4eab-892f-9b3500d1bbb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get any specific dimension\n",
    "MATRIX[0]   # return 1st dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7758e64-da04-498f-9e85-99ea785885dc",
   "metadata": {},
   "source": [
    "#### Type:-3 Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c3c95e-3252-45f1-be59-97f582ec12b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[[3,2],\n",
    "                        [4,7],\n",
    "                        [2,8]]])\n",
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a426a828-f52d-402d-b880-5217f0c3aefe",
   "metadata": {},
   "source": [
    "### Random Tensors\n",
    "\n",
    "why random tensors?\n",
    "because many neural network learn is that they start with tensor fulll of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c86245a5-87f7-4622-b5db-983d9875e3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1562, 0.4496, 0.2041, 0.6427],\n",
       "        [0.6884, 0.9833, 0.2167, 0.9074],\n",
       "        [0.0462, 0.6687, 0.6420, 0.0083]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating random tensor\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab371787-0acf-474d-9df8-129b07c30d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1650, 0.0494, 0.5364],\n",
       "         [0.1302, 0.9885, 0.5283],\n",
       "         [0.6471, 0.1914, 0.8306],\n",
       "         [0.5303, 0.3582, 0.4482]],\n",
       "\n",
       "        [[0.5022, 0.3024, 0.8532],\n",
       "         [0.7110, 0.7376, 0.6559],\n",
       "         [0.2093, 0.0903, 0.9471],\n",
       "         [0.4938, 0.7535, 0.4933]],\n",
       "\n",
       "        [[0.6761, 0.9767, 0.4038],\n",
       "         [0.1034, 0.4707, 0.3470],\n",
       "         [0.2577, 0.7350, 0.0449],\n",
       "         [0.0451, 0.2292, 0.4387]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(3,4,3)) # height, width, color channel\n",
    "random_image_size_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797b3d68-7aed-4f2d-9f07-dc01e12f99b5",
   "metadata": {},
   "source": [
    "### Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07fce65b-71c4-4498-a28f-20bfeaa20558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a tensor full of zeros\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91e1909b-c1e1-4c0a-97c3-05b63fe6e3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a tensor full of ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "beff20da-58b6-44c7-9c62-b4233b50e030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using arange\n",
    "# torch.arange(1,4) this is also work below is more appropreate way\n",
    "one_to_ten = torch.arange(start=0, end=10, step=2)   # did not include the last number\n",
    "one_to_ten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43c80728-9722-49b9-9f28-ecb6f53abbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREARING TENSORS LIKE\n",
    "ten_zeros = torch.zeros_like(one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dab6ff-f608-4701-a4f5-5b5c4aa411ca",
   "metadata": {},
   "source": [
    "### Tensor DataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "deab0a5d-c44f-48e4-befc-1c43d17ef1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0,6.0,9.0], dtype=None, # datatype of the tensor\n",
    "                                              device=\"cpu\",  # cpu or gpu(cuda)\n",
    "                                              requires_grad=False) # track gradient\n",
    "float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7039cf89-3ccd-4e1d-8a02-209e5d7172b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing dtype of an existing tensor and storing it in new variable\n",
    "float_16_tensor = float_32_tensor.type(torch.half) # or torch.float16\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7cb8a2e3-0510-4010-8b6d-e31b212a29c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5], dtype=torch.int32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3,4,5], dtype=torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c606cf27-24ef-4c91-a79e-a91d58f6607a",
   "metadata": {},
   "source": [
    "### Getting info from tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c7a60fa-3205-4cdd-8cbd-051c2a8058da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting datatype\n",
    "int_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "65897158-7a66-44c6-9cb6-2e8d01470cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting device\n",
    "int_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "805a4f28-545d-424e-8b52-1ba18d0f2849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting shape\n",
    "int_32_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed211ce4-ffa6-498e-96b8-53efe35c3a01",
   "metadata": {},
   "source": [
    "### Tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a82f5b-37f0-45bc-be36-6cd83b82c2c1",
   "metadata": {},
   "source": [
    "#### Addition & subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9247075a-4952-4947-91f7-ab3963ce25c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 7, 9])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_1 = torch.tensor([1,2,3])\n",
    "tensor_2 = torch.tensor([4,5,6])\n",
    "# adding two tensors\n",
    "tensor_1 + tensor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0d48716c-a0f4-4317-af59-940f58b3c55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding a constant to a tensor\n",
    "tensor_1 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df4f9102-9e42-4017-a820-67c47e176e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtraction by a constant\n",
    "tensor_1 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f94b66cc-2245-40e4-915f-3af33df0201a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3, -3, -3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtracting two tensors\n",
    "tensor_1 - tensor_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0c84b-b24c-4ffd-b961-fb3a417c556b",
   "metadata": {},
   "source": [
    "#### matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef2809a4-2754-4cd5-94c0-6c74b859cd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element wise mul\n",
    "tensor_1 * tensor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aa4ecf6a-d4c0-480b-b8f1-dcbe3ac422d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix mul\n",
    "torch.matmul(tensor_1, tensor_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed48845-ab88-437b-87dc-ea8a419d2a5d",
   "metadata": {},
   "source": [
    "#### there are two rules that performing matrix multiplication needs to satisfy\n",
    "1. The `inner dimensions` must match.\n",
    "* eg:- (3,2) @ (2,3)\n",
    "2. The resulting matrix has the shape of the `outer dimensions`.\n",
    "* eg:- `(2,3) @ (3,2)` -> `(2,2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ba85f46d-c936-46c3-905c-3b376f1fd649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6505, 0.4544, 0.4590],\n",
       "        [0.5514, 0.3796, 0.3858],\n",
       "        [0.6653, 0.8275, 0.6877]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.rand(3,2), torch.rand(2,3))   # here inner dimensions are same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fcf5a4-7014-4f1f-aa6c-13f3a4dacebf",
   "metadata": {},
   "source": [
    "### One of the most common erros in deep learning is `shape error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5c4bfcf1-dcf1-4786-b299-d9afe9c3129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapes for matrix multipliation\n",
    "tensor_a = torch.rand(3,4)\n",
    "tensor_b = torch.rand(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fc1e3b7f-8ef2-4c62-879e-202d34a21a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_a, tensor_b).shape  # or mm instead of matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcccc517-c48f-4a64-b7b5-414e54cd5d3e",
   "metadata": {},
   "source": [
    "#### Transpose\n",
    "A `Transpose` switches the dimensions of a given tensor.\n",
    " we can solve the issue of shape error by this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9c312bd8-ac58-4aec-ad28-befefca5e508",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_c = torch.rand(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "99b61410-4d7a-4a2b-9f3c-fab413b1d530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3939, 0.3757, 0.5589, 0.6901],\n",
       "        [0.9540, 0.9471, 1.4530, 1.3845],\n",
       "        [0.6095, 0.6301, 0.6755, 0.4319],\n",
       "        [0.9851, 0.9975, 1.1531, 0.9554]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_b, tensor_c.T)   # Transpose tensor_c to do mm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f5e70-436f-48de-af97-b1a3abf1316a",
   "metadata": {},
   "source": [
    "#### Finding min, max, mean, sum, etc(tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "153e7440-b3ff-4ebd-8f46-ee203b7bbe23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding min\n",
    "x = torch.tensor([1,4,6,3]) \n",
    "torch.min(x)  # or x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "70bab62a-7ef2-4bd1-954c-3435bcdc5225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding max\n",
    "x.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b132e77-fcd4-4a04-9eb2-2d9e62422499",
   "metadata": {},
   "source": [
    "##### For finding mean dtype should be either float or complex number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "72278332-6dc8-428e-98e4-67b6006a2e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5000)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding mean\n",
    "torch.mean(x.type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ebe8fbb3-8ed3-4dad-936d-86653533d1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(14), tensor(14))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab0c752-c563-4d27-a31d-d06f0127470b",
   "metadata": {},
   "source": [
    "#### Finding position of min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1e35cdfe-555f-4c5c-a2f4-dfc71b3676e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding position for min value\n",
    "x.argmin(), torch.argmin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6de62bda-af45-4e70-b08b-d511cc50f34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2), tensor(2))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding position for max value\n",
    "x.argmax(), torch.argmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aa9673-a4b9-4cbc-b4d9-5c98f79d1341",
   "metadata": {},
   "source": [
    "#### Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "1. `Reshaping` -> reshapes an input tensor to a defined shape.\n",
    "2. `View` -> Return a view of an input tensor of certain shape but keep the same memory as the original tensor.\n",
    "3. `Stacking` -> Combine multiple tensors on top of each other (vstack) or side by side (hstack).\n",
    "4. `Squeeze` -> removes all `1` dimensions from a tensor.\n",
    "5. `Unsqueeze` -> add a `1` dimension to a target tensor.\n",
    "6. `Permute` -> Return a view of the input with dimensions permuted (swaped) in a certain way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0786c209-397a-452c-b0d3-7d717be07a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a tensor\n",
    "y = torch.arange(1,10)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "667baee7-529c-49f6-b56c-2a69fc926ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping\n",
    "y_reshaped = y.reshape(3,3) # its multiplication should bot exceed original size\n",
    "y_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b30a370-2362-41fc-96c3-263604d545c1",
   "metadata": {},
   "source": [
    "##### changing z will change y because view of a tensor shares same memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8c28726a-fd3a-4c08-9f74-f793465a2ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing view\n",
    "z = y.view(1,9)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "373fa076-45dc-4f64-8327-a3f938b1ab67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack tensors on top (stack default works as vstack another type of hstack)\n",
    "y_stacked = torch.stack([y,y,y], dim=0)\n",
    "y_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6f563c97-02ff-4d93-9f01-d311405fb79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]),\n",
       " tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.squeeze() -> remove all single dimension from a tensor\n",
    "y_reshaped, y_reshaped.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae35d69a-f689-49f7-bad2-846c79e6c85b",
   "metadata": {},
   "source": [
    "#### Indexing (selecting data from tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "72347e3b-202b-4091-a550-39e102682fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a new tensor\n",
    "f = torch.arange(1,10).reshape(1,3,3)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d4cb2d20-1af5-48d9-aa1d-ac93e7ce4741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing on outer dimension\n",
    "f[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "57cf648f-0702-4739-9439-89633ef3f0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing on middle dimension\n",
    "f[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "729f7e07-ce5b-4d54-bbb9-579fa1b1d2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 5, 6]), tensor([[2, 5, 8]]), tensor(2), tensor([1]))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing on most outer dimension\n",
    "f[0,1,:], f[:,:,1], f[0,0,1], f[:,0,0]  # : for getting all the value of that dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be74e3f8-2aa8-47e6-b6eb-84b609cce569",
   "metadata": {},
   "source": [
    "#### Reproducibility (trying to take random out of random)\n",
    "To reduce the randomness in neural network and pytorch we use `random seed` concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d0ebe77e-c450-47a2-83a7-12801c30bd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_tensor_a = torch.rand(3,4)\n",
    "rand_tensor_b = torch.rand(3,4)\n",
    "rand_tensor_a, rand_tensor_b\n",
    "rand_tensor_a == rand_tensor_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "bd0b8e69-7488-47ea-a02a-80a17fbcf654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make some random but reproducible tensors\n",
    "RANDOM_SEED = 42;\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "rand_tensor_c = torch.rand(3,4)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "rand_tensor_d = torch.rand(3,4)\n",
    "rand_tensor_c == rand_tensor_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df4ccc-fc23-4a1a-a16e-b9ec6fe0099b",
   "metadata": {},
   "source": [
    "### Setup device agnostic code\n",
    "divice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac630bb7-2b9c-43cb-a067-f7c5053d0bf8",
   "metadata": {},
   "source": [
    "### Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b23295-49ef-4837-b2b2-58263b21a7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a040e7-1f23-426b-bf82-127b9843b762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30759134-2cb9-49d6-afd3-3a1ee304c044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55826ca-76ac-4514-b817-562763305fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad290e-8b46-4cbe-8498-c69f3c6f2ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee1b92-972e-40ad-b0c6-75cb7d4777b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27752fa-6bd9-483a-8ff5-7b74d2707d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b9ed7-c21d-4aaa-bde8-a418cd43c660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d00314-1c1b-46d1-b718-5ea88ea25a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc2582-653b-4105-b38e-0736510c5ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb5a749-d3f4-4fd8-a4df-61c4274e028b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b977dfd-b291-4b8c-861f-02d362370809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed5669-275d-4027-ac3c-c92fa8cb1b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c8351f-c18b-4c02-ae92-df1b9e9d6722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
